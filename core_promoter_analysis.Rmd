---
title: "Core Promoter Analysis"
subtitle: ".."
author: "Andrey"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    code_folding: hide
    number_sections: true
    toc_float: true
---

``````{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 10,
fig.height = 7,
fig.align = 'center',
dpi = 300,
warning = FALSE,
message = FALSE,
tidy = TRUE,
echo=TRUE,
include = TRUE,
eval = FALSE)
```

# General 

Promoter data used is from ENCODE:

- K562 cell line (cell): two replicates

CAGE-seq was extracted from the R package __ENCODEprojectCAGE__.

```{r}
# cell lines in ENCODE
# install.packages("http://promshift.genereg.net/CAGEr/PackageSource/ENCODEprojectCAGE_1.0.1.tar.gz", repos = NULL) 
library("BSgenome.Hsapiens.UCSC.hg19")
library(ENCODEprojectCAGE)
data(ENCODEhumanCellLinesSamples) 

ENCODEhumanCellLinesSamples
```

# Extracting core set of promoters

Data was extracted from R package __ENCODEprojectCAGE__. 

## CAGEset 

Make a CAGEobject with normalised CTSS and TCs (20bp distance metric) with interquantile widths determined (0.1 - 0.9).

Since the sample sizes may differ, it is important to normalise them.
The normalised data can then be exported as bed graphs to be viewed in the UCSC Genome Browser. 

Raw CAGE data are clustered into groups depending on how faw from each other the calls are. In this case, 20 nt is used as a threshold for one cluster. 0.5 cpm is a minimum amount of (normalised) signal for a cluster to be included in subsequent analysis. 

After the clusters are obtained, promoter width can be determined. Cumulative distribution of TSS is calculated and promoter width is defined as a distance between bottom 10% and top 90% of the distribution.

```{r}
#packages 
library("pacman")
p_load(CAGEr,ENCODEprojectCAGE,BSgenome.Hsapiens.UCSC.hg19)


## Import the ENCODE data into CAGEr object

# make input compatible with importPublicData function
datasets = c("K562", "HepG2", "A549", "GM12878", "MCF-7")
datasets = sapply(datasets, function(x) {rep(x,2)})
datasets = as.vector(datasets)

ENCODEset = importPublicData(source="ENCODE", dataset=datasets, group=rep("cell", times=10), sample=c("K562_cell_rep1", "K562_cell_rep2", "HepG2_cell_rep1", "HepG2_cell_rep2", "A549_cell_rep1","A549_cell_rep2", "GM12878_cell_rep1", "GM12878_cell_rep2", "MCF-7_cell_rep1", "MCF-7_cell_rep2"))

# normalise + iq-width
plotReverseCumulatives(ENCODEset, fitInRange = c(5, 10000), onePlot = TRUE)
## check graph and set alpha:
normalizeTagCount(ENCODEset, method = "powerLaw", fitInRange = c(5, 10000), alpha = 1.17, T = 1*10^6)

#clustering CTSSs 
clusterCTSS(object = ENCODEset, threshold = 1, thresholdIsTpm = TRUE, nrPassThreshold = 1, 
            method = "distclu", maxDist = 20, removeSingletons = TRUE, keepSingletonsAbove = 5)

# determining TC widths
cumulativeCTSSdistribution(ENCODEset, clusters = "tagClusters")
quantilePositions(ENCODEset, clusters = "tagClusters", qLow = 0.1, qUp = 0.9)

# consensus clusters
aggregateTagClusters(ENCODEset, tpmThreshold=0.5, qLow = 0.1, qUp = 0.9)

### save dataset 
saveRDS(ENCODEset, file = "../data/basic/ENCODE_SET.rds")

```

## Quality control

Correlation between the samples (here with CAGEr function), library sizes, number of TCs, and distribution of TC widths.

```{r}
# packages
suppressPackageStartupMessages(library(pacman)) 
p_load(CAGEr,BSgenome.Hsapiens.UCSC.hg19,tidyverse,wesanderson,gridExtra, ggplot2)

# load in CAGE object 
ENCODEset = readRDS("../data/basic/ENCODE_SET.rds")

#correlation between samples  
corr.m <- plotCorrelation(ENCODEset, what = "consensusClusters", samples = "all", method = "pearson")

# merge samples with corr coef. >= 0.9. NB! results get erased, thus previous steps must be repeated 
mergeSamples(ENCODEset, mergeIndex = c(1,1,2,2,3,3,4,4,5,6) , mergedSampleLabels = c("K562_cell", "HepG2_cell", "A549_cell", "GM12878_cell", "MCF-7_cell_rep1", "MCF-7_cell_rep2"))

### library sizes and TCs
# Number and widths of TCs:
sample.names = as.character(sampleLabels(ENCODEset))
sample.names = sample.names[-6] # drop 2nd replicate of MCF-7 due to low correlation 
.getClusters = function(x){
  tc = tagClusters(ENCODEset, sample = x, returnInterquantileWidth = TRUE, qLow = 0.1, qUp = 0.9)
  tc_subset = which(tc$chr != "chrM" & tc$chr != "chrX") 
  tc = tc[tc_subset, ] 
  return(tc) 
}
tc_list = lapply(sample.names, .getClusters)
names(tc_list) = sample.names
#save TC clusters 
saveRDS(tc_list, file = "../data/basic/tc_list.rds")


# make df for ggplot
meta <- data.frame(libsize = librarySizes(ENCODEset)/1000000, numTCs = unlist(lapply(tc_list, nrow)), samples = as.character(sampleLabels(ENCODEset)))
## Plot lib size & number of TCs
cols = wes_palette("Rushmore1")[4:5] # colour
p <- ggplot(meta, aes(x = samples, y = libsize)) + geom_bar(stat = "identity", fill = cols[1]) + theme_bw() + ggtitle("Library sizes for all samples") + theme(axis.text.x = element_text(angle = 75, hjust = 1)) + ylab("Library sizes (in million)")
p1 <- ggplot(meta, aes(x = samples, y = numTCs)) + geom_bar(stat = "identity", fill = cols[2]) + theme_bw() + ggtitle("Number of TCs for all samples") + theme(axis.text.x = element_text(angle = 75, hjust = 1)) + 
   ylab("Number of TCs")
png("../data/qc/libSizeTCnumbers_5_cell_lines_higher threshold.png")
grid.arrange(p,p1, ncol = 2, nrow = 1)
dev.off()




```

## Produce a heatmap of correlations between all cell types 
```{r}
library(pacman)
p_load(CAGEr,BSgenome.Hsapiens.UCSC.hg19, ggplot2, reshape2)

ENCODEset = readRDS("../data/basic/ENCODE_SET.rds")

### Plot a correlation heatmap among consensus clusters 
df = as.data.frame(ENCODEset@consensusClustersTpmMatrix)
df = df[,-6]
corr_matrix = cor(df)

# lower half of matrix 
get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
# higher half of matrix 
get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

# reorder the correlation matrix
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}

### Hetamap

# reorder corr_matrix 
corr_matrix = reorder_cormat(corr_matrix)
# melt corr matrix 
upper_tri = get_upper_tri(corr_matrix)
corr_matrix_melted = melt(upper_tri, na.rm = TRUE) 
# round coefficiencts
corr_matrix_melted$value = unlist(lapply(corr_matrix_melted$value, function(x){round(x, digits = 2)}))

heatmap = ggplot(data = corr_matrix_melted, aes(Var2, Var1, fill = value)) +
          geom_tile(color="white") +
          scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
          midpoint = 0.5, limit = c(0,1), space = "Lab", name="Pearson\nCorrelation") + 
          
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
          coord_fixed()
          ggsave("../data/qc/cons_cluster_corr.png")

# heatmap w correlation coefficients
 heatmpap_coef = heatmap + 
 geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
 theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.5, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))
 
  ggsave("../data/qc/cons_cluster_corr_coef.png")
          

```




Correlation matrix. Since the samples are technical replicates, the correlation coefficient is close to 1, as expected. The MCF-7 line failed to demonstrate sufficient correlation level, thus its replicates were not merged and 2nd replicate was removed from subsequent analysis. 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/figures/consensusClusters_raw_values_pairwise_correlation.png")
 grid.raster(img)
```

Correlation heatmap among consensus clusters. Whereas the majority of samples are relatively correlated, the HepG2 cell line shows nearly no correlation to other cell lines. 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/qc/cons_cluster_corr_coef.png")
 grid.raster(img)
```

Library sizes 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/qc/libSizeTCnumbers_K562.png")
 grid.raster(img)
```

Cumulative distribution number of CTSS with respect to amount of CAGE signal
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/figures/ScreenShot.png")
 grid.raster(img)
```

IQ width histograms
```{r}
# packages
suppressPackageStartupMessages(library(pacman)) 
p_load(tidyverse, ggplot2)
tc_list = readRDS("../data/basic/tc_list.rds")

#overlayed histogram 
iq_width = as.numeric(tc_list[[1]]$interquantile_width)
sample = rep('sample_1', each = length(tc_list[[1]]$interquantile_width))
iq_1_df = data.frame(cbind(iq_width, sample))
colnames(iq_1_df) = c("iq_width", "sample")

iq_width = as.numeric(tc_list[[2]]$interquantile_width)
sample = rep('sample_2', each = length(tc_list[[2]]$interquantile_width)) 
iq_2_df = data.frame(cbind(iq_width, sample))
colnames(iq_2_df) = c("iq_width", "sample")

iq_tot = data.frame(rbind(iq_1_df, iq_2_df))
colnames(iq_tot) = c("iq_width", "sample")
iq_tot$iq_width = as.numeric(levels(iq_tot$iq_width))[iq_tot$iq_width]

p_1 = ggplot(data = iq_tot, aes(x = iq_width, fill = sample)) +
   geom_histogram(alpha = 0.35, binwidth = 1, breaks=seq(0, 30, by = 1), position = "identity") + 
   coord_cartesian(xlim = c(0,30)) + 
   labs(x="iq_width") +
   labs(title = "Histogram overlay for 2 samples")
   ggsave("../data/figures/hist_overlay.png")
   


## overlayed dens_plots 

p_2 = ggplot(data = iq_tot, aes(x = iq_width, fill = sample)) +
   geom_density(alpha = 0.35, position = "identity") + 
   coord_cartesian(xlim = c(0,30)) + 
   labs(x="iq_width") +
   labs(title = "Density plots overlayed for 2 samples")
   ggsave("../data/figures/dens_overlay.png")

```
Overlayed histograms of 2 samples
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/figures/hist_overlay.png")
 grid.raster(img)
```

Overlayed Density Plots 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/figures/dens_overlay.png")
 grid.raster(img)
```

## Genomic features mapping

```{r}
suppressPackageStartupMessages(library(pacman)) 
p_load(heatmaps, rtracklayer, GenomicRanges, seqPattern, ChIPseeker, 
       TxDb.Hsapiens.UCSC.hg19.knownGene, clusterProfiler)

#annotate peaks to TSS data
ENCODE_TSS = readRDS("../data/basic/ENCODE_TSS.rds")
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
.annotation_plotter = function(x){
peakAnno = annotatePeak(ENCODE_TSS[[x]], tssRegion=c(-3000, 500), TxDb=txdb)
p = plotAnnoBar(peakAnno)
    png(paste0("../data/qc/genomic_features/chip_seq_anno_", names(ENCODE_TSS[x]), ".png"))
print(p)
dev.off()
}
n = names(ENCODE_TSS)
lapply(seq_along(ENCODE_TSS), .annotation_plotter)

```

Genomic feature distribution for the K562 cell line
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
library("png")
library("grid")
img <- readPNG("../data/qc/genomic_features/chip_seq_anno_K562_cell.png")
 grid.raster(img)
```

## Tracks

Tracks are found here: `../data/tracks/`
```{r}
# packages
suppressPackageStartupMessages(library(pacman)) 
p_load(CAGEr,BSgenome.Hsapiens.UCSC.hg19)
# load in cage object
ENCODEset = readRDS("../data/basic/ENCODE_SET.rds")

# export track of counts:
exportCTSStoBedGraph(ENCODEset, values = "normalized", format = "bedGraph", oneFile = FALSE)
# export track of TC width (iq too)
exportToBed(object = ENCODEset, what = "tagClusters", qLow = 0.1, qUp = 0.9, oneFile = FALSE)
```

# Data analysis 
## GRanges 

The tag clusters are extracted from the CAGEset object for downstream analysis.
In order to match tag clusters to actual genomic sequences, the hg19 assembly of human genome is used.
Dominant TSS is defined for each cluster (position with the highest amount of tags) and stored as GRanges object. Then, flanking seqeunces are retrived (250 bp upstream/downstream) with respect to the dominant TSS.
It is important to trim the sequences which fall out of the range of chromosome lengths. 

```{r}
# packages
suppressPackageStartupMessages(library(pacman)) 
p_load(BSgenome.Hsapiens.UCSC.hg19, GenomicRanges)
tc_list = readRDS("../data/basic/tc_list.rds")
# retrieve the sequences of interest from the reference genome 
genome = BSgenome.Hsapiens.UCSC.hg19

### get positions of dominant CTSS
.get_GRanges = function(x){
                    gr = GRanges(seqnames = x$chr,
                    ranges = IRanges(start = x$dominant_ctss,
                    end = x$dominant_ctss),
                    strand = x$strand,
                    interquantileWidth = x$interquantile_width,
                    seqlengths = seqlengths(genome))
                    
                    ## append metadata columns to Granges object
                    mcols(gr) = x[,(6:12)]
                    
                    #remove sequences out of bound 
                    gr_trimmed = trim(promoters(gr, upstream = 250, downstream = 250))
                    gr1 = which(width(gr_trimmed)==500)
                    gr_trimmed = gr_trimmed[gr1]
                    #randomise the chromosome order 
                    gr_trimmed_rand <- sample(gr_trimmed)
                   
                    return(gr_trimmed_rand)
}

ENCODE_TSS = lapply(tc_list, .get_GRanges)
chr_set = paste("chr", c(1:22), sep = "")
ENCODE_TSS = lapply(ENCODE_TSS, function(x){x=x[x@seqnames %in% chr_set]})

# get promoter sequences 
.getSeqs = function(x){
  sequences = getSeq(genome, x)
  
  return(sequences)
}
ENCODE_TSS_flank_seq = lapply(ENCODE_TSS, .getSeqs)

saveRDS(ENCODE_TSS, file = "../data/basic/ENCODE_TSS.rds")
saveRDS(ENCODE_TSS_flank_seq, file = "../data/basic/ENCODE_TSS_flank_seq.rds")
```

## Dinucleotide heatmaps & pattern occurance  
ChIPSeeker package allows to determine the locations of TF binding sites or specific histone modifications genome-wide and produce annotations for the TSS dataset (i.e. to which genomic location each TSS corresponds). Annotated peaks can further be filtered (e.g. Promoters <= 1kb from the TSS). Filtering step considerably decreases the number of clusters (~43%). 

The Heatmaps package is used for plotting data. Heatmaps are produced for different nucleotide patterns and smoothed using Gaussian blur. Coverage heatmaps are produced to observe the distribution of iq_width.  
```{r}
# packages 
suppressPackageStartupMessages(library(pacman))
p_load(heatmaps, rtracklayer, GenomicRanges, seqPattern, ChIPseeker, TxDb.Hsapiens.UCSC.hg19.knownGene, clusterProfiler)
ENCODE_TSS = readRDS("../data/basic/ENCODE_TSS.rds")

# filter the dataset to contain only the 'promoter' annotated TSS
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
.prom_filter = function(x){
peakAnno <- annotatePeak(x, tssRegion=c(-3000, 500), TxDb=txdb) 
peak_Anno_prom = which(peakAnno@anno$annotation == "Promoter (<=1kb)")
peakAnno@anno = peakAnno@anno[peak_Anno_prom]
peakAnno_sorted = peakAnno@anno[with(peakAnno@anno, order(interquantile_width))]
return(peakAnno_sorted)
}
ENCODE_promoters = lapply(ENCODE_TSS, .prom_filter)

# verification step: what % of clusters were removed? 
lib_size_unf = c()
lib_size_filt = c()
for(i in 1:length(ENCODE_TSS)){
   lib_size_unf[i] = length(ENCODE_TSS[[i]])
   lib_size_filt[i] = length(ENCODE_TSS_promoters[[i]])
}
print((lib_size_unf - lib_size_filt)/lib_size_unf * 100)
saveRDS(ENCODE_promoters, file = "../data/basic/ENCODE_TSS_promoters.rds")

##  sequences for annotated promoters 
ENCODE_promoters_seq = lapply(ENCODE_promoters, function(x){getSeq(genome, x)})
saveRDS(ENCODE_promoters_seq, "../data/basic/ENCODE_promoters_seq.rds")

## create GRanges object for coverage heatmap
tc_list = readRDS("../data/basic/tc_list.rds")
.granges = function(x) {
GRanges(seqnames = x$chr, 
             ranges = IRanges(start = x$q_0.1, end = x$q_0.9),
             strand = x$strand, seqlengths = seqlengths(genome))
}
coverage_ranges = lapply(tc_list, .granges)

.heatmap_plotter = function(x){ 
   
coords = c(-250, 250)
patrns = c("TA", "CG", "SS", "WW")
pat_list = lapply(patrns, function(y){PatternHeatmap(ENCODE_promoters_seq[[x]], y, coords = coords)})
#coverage heatmap
cov_hm = CoverageHeatmap(ENCODE_promoters[[x]], coverage_ranges[[x]], coords = c(-250, 250), label = "TC coverage")

#smooth pattern heatmaps (not coverage) 
pat_list = lapply(pat_list, function(y){ smoothHeatmap(y, output.size=c(floor(length(ENCODE_promoters_seq[[x]])/2), 250), algorithm="kernel")})
plot_list = append(pat_list, cov_hm)

#plotting step
png(paste0("../data/figures/heatmaps/promoter_patterns_", names(tc_list[x]), ".png"), height=20, width=40, units="cm", res=150)
plotHeatmapList(plot_list, groups = c(1,1,2,2,3), color = list("Blues","Greens", "Oranges"), cex.label = list(1,1,1))
dev.off()
}
lapply(seq_along(tc_list), .heatmap_plotter)

```

Heatmaps for clusters assigned to promoter regions (<=1kb) + TC coverage (K562 cell line)
```{r fig.width=10, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/figures/heatmaps/promoter_patterns_K562_cell.png")
 grid.raster(img)
```
 
## POLII collection of TF motif heatmaps
Transcription factor binding sites are extracted from the JASPAR database and converted to position-weight matrices.
```{r}
## PolII collection from JASPAR
library(pacman)
p_load(TFBSTools, JASPAR2018, heatmaps, seqPattern)

opts = list()
opts[["collection"]] = "POLII"
opts[["all_versions"]] = FALSE
PFMatrixList = getMatrixSet(JASPAR2018, opts)
PFMatrixList

# convert to PWM
polII.l = toPWM(PFMatrixList, pseudocounts = 0.8)
polII_pwm.l = lapply(polII.l, function(x) return(as.matrix(x)))

# extract names of matrices
motifs = lapply(polII.l, function(x) x@name)
names(polII_pwm.l) = motifs

# plot seqlogo for all motifs
library("ggseqlogo")
for (i in 1:length(PFMatrixList)) {
    pdf(paste0("../data/figures/seqlogo_", names(polII_pwm.l[i]), 
        ".pdf"), height = 6, width = 8)
    print(ggseqlogo(as.matrix(PFMatrixList[[i]])))
    dev.off()
}

#save PolII motifs as RDS object 
saveRDS(polII_pwm.l, "../data/basic/POLII_PWM.rds")

# read promoter sequences file 
ENCODE_promoters_seq = readRDS("../data/basic/ENCODE_promoters_seq.rds")

### heatmaps
for (i in c(1:length(polII_pwm.l))) {
pbs_scores = motifScanScores(TSS_prom_seqs, motifPWM = polII_pwm.l[[i]])

# convert TBP scores to heatmaps object
hm.l = new("Heatmap", image = pbs_scores, coords = as.integer(c(-250, 250)), nseq = nrow(pbs_scores), label = paste(names(polII_pwm.l[i]), "pwm", sep = " "), metadata = list())

# set smoothing and plotting
hm_smoothed.l = smoothHeatmap(hm.l, output.size = c(floor(length(TSS_prom_seqs)/2), 250))
scale(hm_smoothed.l) = c(40, 60)

png(paste0("../data/qc/", names(polII_pwm.l[i]), ".png"), height=20, width=20, units="cm", res=300)
plotHeatmapList(hm_smoothed.l, color = "PuBu", legend = TRUE, legend.width = 0.3)
dev.off()
}

```

Annotation proportions from JASPAR. The majority of calls represent promoter sequence 
```{r fig.width=10, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/genomic_features/chip_seq_anno_K562_cell.png")
 grid.raster(img)
```

Heatmap represneting the occurance of TATA-box motif within proximal promoter regions (<= 1kb).
```{r fig.width=10, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/TATA-Box.png")
 grid.raster(img)
```

### kmeans
Apply k-means clustering to the heatmaps produced above (partition into 2 groups). This leads to reduction of noise and better partition of promoter sequences. Each heatmap was clustered based on the positions where the respective motif is found.   
```{r}
library(pacman)
p_load(TFBSTools, ggseqlogo, heatmaps, BSgenome.Hsapiens.UCSC.hg19, seqPattern)

genome = BSgenome.Hsapiens.UCSC.hg19
polII_pwm.l = readRDS("../data/basic/POLII_PWM.rds")
# two sets of sequences for a heatmap
ENCODE_promoters_seq = readRDS("../data/basic/ENCODE_promoters_seq.rds")

### check which motifs occur in at least 10% of promoters (85% match)
#known motif positions for pattern search
pos_list = list(c(268, 290), c(242, 258), c(140, 200), c(150, 200), 
                c(273, 287), c(200, 230), c(220, 250), c(255, 265), 
                c(266, 275), c(290, 300), c(240, 260), c(200, 240), c(150, 250))
names(pos_list) = names(polII_pwm.l)

.pattern_search = function(x){
seq_ratio_vec = c()
for(i in 1:length(ENCODE_promoters_seq)){
sub_seq = subseq(ENCODE_promoters_seq[[i]], start = pos_list[[x]][1], end = pos_list[[x]][2])     
pbs_scores = motifScanScores(sub_seq, motifPWM = polII_pwm.l[[x]])
pbs_scores = split(pbs_scores, rep(1:nrow(pbs_scores), each = ncol(pbs_scores)))
filter_list = lapply(pbs_scores, function(y){return(any(y>85))})
filter_list = factor(as.character(filter_list))
seq_ratio = floor(as.numeric(summary(filter_list)["TRUE"])/length(pbs_scores)*100)
if(is.na(seq_ratio)){
   seq_ratio = 0
}
seq_ratio_vec[i] = seq_ratio
}
return(seq_ratio_vec)
}
score_list = lapply(seq_along(polII_pwm.l), .pattern_search)

## construct a data frame
col_names = names(ENCODE_promoters_seq)
motif_data = do.call(rbind, score_list)
motif_data = as.data.frame(motif_data, row.names = names(polII_pwm.l))   
colnames(motif_data) = names(ENCODE_promoters_seq)
motif_data

saveRDS(motif_data, file = "../data/basic/POLII_motifs_df.RDS")
motif_data = readRDS("../data/basic/POLII_motifs_df.RDS")

### construct heatmaps ###
.RNAP_motifs = function(x) {
for (i in c(1:length(polII_pwm.l))) {
# two score matrices - one for clustering (motif-specific positions), one for plotting   
TSS_prom_seqs_subset = subseq(ENCODE_promoters_seq[[x]], start=pos_list[[i]][1], end=pos_list[[i]][2])   
   
pbs_scores = motifScanScores(ENCODE_promoters_seq[[x]], motifPWM = polII_pwm_subset[[i]])
pbs_scores_subset = motifScanScores(TSS_prom_seqs_subset, motifPWM = polII_pwm_subset[[i]])

clusters = kmeans(pbs_scores_subset, centers = 2)
if (clusters$ifault != 0) {
   print("clustering unsuccessful")
   next
   }
mat = pbs_scores[order(clusters$cluster),]

hm.l = new("Heatmap", image = mat, coords = as.integer(c(-250, 250)), nseq = nrow(mat), label = paste(names(polII_pwm_subset[i]), "pwm", sep = " "), metadata = list())

# set smoothing and plotting
hm_smoothed.l = smoothHeatmap(hm.l, output.size = c(floor(length(TSS_prom_seqs)/2), 250))

if(grepl("BRE", names(polII_pwm_subset[i])) | grepl("GC", names(polII_pwm_subset[i])) | grepl("DPE", names(polII_pwm_subset[i])) | grepl("INR", names(polII_pwm_subset[i])) | grepl("MTE", names(polII_pwm_subset[i]))){
   scale(hm_smoothed.l) = c(50, 90)
   } else{
      scale(hm_smoothed.l) = c(40, 60)
   }

png(paste0("../data/qc/clustered_hms/all_cell_types/", names(polII_pwm_subset[i]), "_", names(ENCODE_promoters_seq[x]), ".png"), height=20, width=20, units="cm", res=200)
plotHeatmapList(hm_smoothed.l, color = "PuBu", legend = TRUE, legend.width = 0.3, 
                partition = clusters$size, partition.lines = TRUE, 
                partition.legend = TRUE, legend.pos = "r")
dev.off()
   }
}

lapply(seq_along(ENCODE_promoters_seq), .RNAP_motifs)

```
Percentage of sequences that contain a given motif (at 85% match) across cell types
```{r, eval=TRUE}
motif_data = readRDS("../data/basic/POLII_motifs_df.RDS")
motif_data
```

Clustered heatmaps

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/clustered_hms/TATA-Box.png")
 grid.raster(img)
```

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/clustered_hms/XCPE1.png")
 grid.raster(img)
```

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/clustered_hms/GC-box.png")
 grid.raster(img)
```

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/clustered_hms/BREu.png")
 grid.raster(img)
```

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/clustered_hms/BREd.png")
 grid.raster(img)
```

### add motif data to GRanges object
Data are stored as a matrix of seqs x motifs with boolean values indicating whether a given motif is found in a sequence with >85% match. 
```{r}
suppressPackageStartupMessages(library(pacman))
p_load(TFBSTools, BSgenome.Hsapiens.UCSC.hg19, seqPattern)
ENCODE_promoters = readRDS("../data/basic/ENCODE_promoters.rds")
ENCODE_promoters_seq = readRDS("../data/basic/ENCODE_promoters_seq.rds")
genome = BSgenome.Hsapiens.UCSC.hg19
polII_pwm.l = readRDS("../data/basic/POLII_PWM.rds")
names(ENCODE_promoters) = names(ENCODE_promoters_seq)

#known motif positions for pattern search
pos_list = list(c(268, 290), c(242, 258), c(140, 200), c(150, 200), 
                c(273, 287), c(200, 230), c(220, 250), c(255, 265), 
                c(266, 275), c(290, 300), c(240, 260), c(200, 240), c(150, 250))
names(pos_list) = names(polII_pwm.l)


# assign boolean value to each sequence for each motif 
promoters_motif_data = lapply(ENCODE_promoters, function(x){x=x[,-c(1:18)]})
.patrns = function(x){
motif_name = names(polII_pwm.l[x]) # remove
filter_list = c()   # remove 
sub_seq = subseq(ENCODE_promoters_seq[[i]], start = pos_list[[x]][1], end = pos_list[[x]][2])     
pbs_scores = motifScanScores(sub_seq, motifPWM = polII_pwm.l[[x]])
filter_list = apply(pbs_scores, 1, function(y){return(any(y>85))})
return(filter_list)
}
for(i in 1:length(promoters_motif_data)){
score_list = lapply(seq_along(polII_pwm.l), .patrns)
names(score_list) = names(polII_pwm.l)
mcols(promoters_motif_data[[i]]) = score_list
}
names(promoters_motif_data) = names(ENCODE_promoters)
saveRDS(promoters_motif_data, "../data/analysis/promoters_motif_data.RDS")

```


## CpG island analysis 
```{r}
# load packages 
library(pacman)
p_load(BSgenome.Hsapiens.UCSC.hg19, GenomicRanges, heatmaps, seqPattern, ggplot2, reshape2, TxDb.Hsapiens.UCSC.hg19.knownGene, clusterProfiler, org.Hs.eg.db)
genome = BSgenome.Hsapiens.UCSC.hg19
ENCODE_promoters = readRDS("../data/basic/ENCODE_promoters.rds")
ENCODE_promoters_seq = readRDS("../data/basic/ENCODE_promoters_seq.rds")

#construct a dataframe 
cpg_data = read.delim("../data/basic/cpgIslandExt.txt", header = FALSE)
col_headings = c("bin", "chrom", "chromStart", "chromEnd", "name", "length",  "cpgNum", "gcNum", "perCpg", "perGc", "obsExp")
names(cpg_data) = col_headings

# create GRanges object for CpG islands 
CpG_set = GRanges(seqnames = cpg_data$chrom, ranges = IRanges(start = cpg_data$chromStart, end = cpg_data$chromEnd), seqlengths = seqlengths(genome))
mcols(CpG_set) = cpg_data[,c(5:11)] # set metadata columns 
CpG_set = sample(CpG_set) # randomise chromosome order

# keep chr 1:22 
chr_set = paste("chr", c(1:22), sep = "")
CpG_set = CpG_set[CpG_set@seqnames %in% chr_set]
CpG_set = CpG_set[order(CpG_set$length)] # sort CpG islands by length
# filter CGIs 
CpG_set_1 = CpG_set[CpG_set$length<2000 & CpG_set$obsExp>0.65]


### make correlation plots 
cor_mat = cor(cpg_data[,6:11])

# lower half of matrix 
get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
# higher half of matrix 
get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

# melt corr matrix 
upper_tri = get_upper_tri(cor_mat)
corr_matrix_melted = melt(upper_tri, na.rm = TRUE) 

heatmap = ggplot(data = corr_matrix_melted, aes(Var2, Var1, fill = value)) +
          geom_tile(color="white") +
          scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
          midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation") + 
          
          theme_minimal() +
          theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
          coord_fixed()
          ggsave("../data/qc/cpg_corr.png")

## histogram of CpG island lengths 
p = ggplot(data = cpg_data) +
   geom_histogram(aes(x=cpg_data$length), alpha = 0.5, 
                  breaks = seq(0, 45000, by=50), binwidth = 100, position = "identity", 
                  color = "black", fill = "blue") +
      coord_cartesian(xlim = c(0,4000)) +
      labs(x="length of CpG island") 
   ggsave("../data/qc/cpg_island_hist_1.png")
   

## histogram of pbs/exp ratio (>0.65 is requred)
p = ggplot(data = cpg_data) +
   geom_histogram(aes(x=cpg_data$obsExp), alpha = 0.5, 
                  breaks = seq(0, 3, by=0.1), position = "identity", 
                  color = "black", fill = "blue") +
      labs(x="obs/exp ratio") 
   ggsave("../data/qc/cpg_ratio_hist_1.png")

   
## find overlapping sequences and add to GRanges object
.cgi_search = function(x){
hits = findOverlaps(ENCODE_promoters[[x]], CpG_set)
overlaps = pintersect(ENCODE_promoters[[x]][queryHits(hits)], CpG_set[subjectHits(hits)], ignore.strand=TRUE)
percentOverlap = width(overlaps) / width(ENCODE_promoters[[x]][queryHits(hits)])
# add empty columns for cpg length, etc., then fill them 
ENCODE_promoters[[x]]$CGI = rep(FALSE, times = length(ENCODE_promoters[[x]]))
ENCODE_promoters[[x]]$CGI_overlap = rep(0, times = length(ENCODE_promoters[[x]]))
ENCODE_promoters[[x]]$CGI_length = rep(0, times = length(ENCODE_promoters[[x]]))

for(i in 1:length(hits@from)){
   ENCODE_promoters[[x]]$CGI[hits@from[i]]=TRUE
   ENCODE_promoters[[x]]$CGI_overlap[hits@from[i]]=round(percentOverlap[[i]], digits = 2)
   ENCODE_promoters[[x]]$CGI_length[hits@from[i]]=CpG_set$length[hits@to[i]]
}
return(ENCODE_promoters[[x]]) 
}
ENCODE_promoters = lapply(seq_along(ENCODE_promoters), .cgi_search)
names(ENCODE_promoters) = names(ENCODE_promoters_seq)
saveRDS(ENCODE_promoters, "../data/basic/ENCODE_promoters.rds")
# create a separate object for CGIs 
promoters_CGI_data = lapply(ENCODE_promoters, function(x){x=x[,16:18]})
names(promoters_CGI_data) = names(ENCODE_promoters)
saveRDS(promoters_CGI_data, "../data/analysis/promoters_CGI_data.rds") # NB: around 85% of promoters appear to be overlapped by CGI

## COVERAGE HEATMAP
ENCODE_promoters = lapply(ENCODE_promoters, function(x){x=x[order(x$CGI_overlap)]})
ENCODE_promoters_df = lapply(ENCODE_promoters, as.data.frame)

#create GRanges object for iq-width
.granges = function(x) {
   GRanges(seqnames = x$seqnames, ranges = IRanges(start = x$q_0.1, end = x$q_0.9), strand = x$strand, seqlengths = seqlengths(genome))
}
coverage_ranges = lapply(ENCODE_promoters_df, .granges)
.cov_hm_plot = function(x){
cov_hm1 = CoverageHeatmap(ENCODE_promoters[[x]], CpG_set_1, label = "CpG coverage", coords = c(-250, 250))
cov_hm2 = CoverageHeatmap(ENCODE_promoters[[x]], coverage_ranges[[x]], label = "IQ-width", coords = c(-250, 250), weight=1)
png(paste0("../data/qc/cpg_coverage_hms/by_overlap/CGI_", names(ENCODE_promoters[x]), ".png"), 
    height=20, width=20, units="cm", res=300)
plotHeatmapList(list(cov_hm1, cov_hm2), groups = c(1,2), color = list("PuBu", "Oranges"), cex.label = list(1,1))
dev.off()
}
lapply(seq_along(ENCODE_promoters), .cov_hm_plot)


### ANALYSE PROMOTERS WITHOUT CGIs
# create a subset without CGI 
promoters_no_CGI = lapply(ENCODE_promoters, function(x){x=x[x$CGI==FALSE]})
promoters_no_CGI_seq = lapply(promoters_no_CGI, function(x){getSeq(genome, x)})
names(promoters_no_CGI) = names(ENCODE_promoters)

# motif search 
pos_list = list(c(268, 290), c(242, 258), c(140, 200), c(150, 200), 
                c(273, 287), c(200, 230), c(220, 250), c(255, 265), 
                c(266, 275), c(290, 300), c(240, 260), c(200, 240), c(150, 250))
names(pos_list) = names(polII_pwm.l)

.pattern_search = function(x){
seq_ratio_vec = c()
for(i in 1:length(promoters_no_CGI_seq)){
sub_seq = subseq(promoters_no_CGI_seq[[i]], start = pos_list[[x]][1], end = pos_list[[x]][2])     
pbs_scores = motifScanScores(sub_seq, motifPWM = polII_pwm.l[[x]])
pbs_scores = split(pbs_scores, rep(1:nrow(pbs_scores), each = ncol(pbs_scores)))
filter_list = lapply(pbs_scores, function(y){return(any(y>85))})
filter_list = factor(as.character(filter_list))
seq_ratio = floor(as.numeric(summary(filter_list)["TRUE"])/length(pbs_scores)*100)
if(is.na(seq_ratio)){
   seq_ratio = 0
}
seq_ratio_vec[i] = seq_ratio
}
return(seq_ratio_vec)
}
score_list = lapply(seq_along(polII_pwm.l), .pattern_search)
## construct a data frame (no cpg)
col_names = names(ENCODE_promoters_seq)
motif_data_no_cpg = do.call(rbind, score_list)
motif_data_no_cpg = as.data.frame(motif_data_no_cpg, row.names = names(polII_pwm.l))   
colnames(motif_data_no_cpg) = names(ENCODE_promoters_seq)


## ClusterProfiler analysis 
txdb = TxDb.Hsapiens.UCSC.hg19.knownGene
genes = promoters_no_CGI[[5]]$geneId
all_genes = ENCODE_promoters[[5]]$geneId

# cellular component
ego1 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  ont = "CC", pAdjustMethod = "BH", pvalueCutoff  = 0.005, qvalueCutoff  = 0.05, readable = TRUE)
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_CC1.png", height=20, width=20, units="cm", res=200)
barplot(ego1, showCategory=12)
dev.off()
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_CC2.png", height=20, width=20, units="cm", res=200)
dotplot(ego1)
dev.off()

# molecular function 
ego2 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  ont = "MF", pAdjustMethod = "BH", pvalueCutoff  = 0.01, qvalueCutoff  = 0.05, readable = TRUE)
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_MF1.png", height=20, width=40, units="cm", res=200)
barplot(ego2, showCategory=10)
dev.off()
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_MF2.png", height=20, width=40, units="cm", res=200)
dotplot(ego2)
dev.off()

# biological process
ego3 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  ont = "BP", pAdjustMethod = "BH", pvalueCutoff  = 0.01, qvalueCutoff  = 0.05, readable = TRUE)
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_BP1.png", height=20, width=20, units="cm", res=200)
barplot(ego3, showCategory=10)
dev.off()
png("../data/figures/GO_analysis/MCF_promoters_no_cpg_BP2.png", height=20, width=20, units="cm", res=200)
dotplot(ego3)
dev.off()
```

Coverage heatmap for CpG islands and IQ-width for K562 cells (sorted by degree of overlap)
Notably, around 85% of promoters appear to have CpG islands and the heatmap indicates that they are centered at TSS. 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/qc/cpg_coverage_hms/by_overlap/CGI_K562_cell.png")
 grid.raster(img)
```

Gene onthology analysis on the subset of promoters without CGI

- Cellular Compartment 
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/figures/GO_analysis/promoters_no_cpg_CC1.png")
 grid.raster(img)
```
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/figures/GO_analysis/promoters_no_cpg_CC2.png")
 grid.raster(img)
```
- Biological process
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/figures/GO_analysis/promoters_no_cpg_BP1.png")
 grid.raster(img)
```

```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/figures/GO_analysis/promoters_no_cpg_BP2.png")
 grid.raster(img)
```


## All human promoter motifs 

```{r}
library(pacman)
p_load(TFBSTools, JASPAR2018, heatmaps, seqPattern, ggplot2, tidyverse, BSgenome.Hsapiens.UCSC.hg19)

### retrieve all H.Sapiens sequence motifs from JASPAR 
opts = list()
opts[["species"]] = "9606"
opts[["all_versions"]] = FALSE
PFMatrixList = getMatrixSet(JASPAR2018, opts)
PFMatrixList

# convert to PWM
hs_data = toPWM(PFMatrixList, pseudocounts = 0.8)
hs_data_pwm = lapply(hs_data, function(x) return(as.matrix(x)))

# extract names of matrices
motifs = lapply(hs_data, function(x) x@name)
names(hs_data_pwm) = motifs

# extract promoter sequences (1 sample)
TSS_prom_seqs = readRDS("../data/basic/peakAnno_1kb_prom_seqs.rds")

### sort motifs with >=90% score in at least 10% of promoters
pattern_search = function(x) {
pbs_scores = motifScanScores(TSS_prom_seqs, motifPWM = x)
pbs_scores = split(pbs_scores, rep(1:nrow(pbs_scores), each = ncol(pbs_scores)))
filter_list = lapply(pbs_scores, function(y){return(any(y>90))})
filter_list = factor(as.character(filter_list))
seq_ratio = floor(as.numeric(summary(filter_list)["TRUE"])/length(pbs_scores)*100)
if(is.na(seq_ratio)){
   seq_ratio = 0
}
return(seq_ratio)
}

## construct a data frame 
motif_name = names(hs_data_pwm)
perc_occurance = lapply(hs_data_pwm, pattern_search)
motif_data = cbind(motif_name, perc_occurance)
motif_data = data.frame(cbind(motif_name, perc_occurance), row.names = NULL)
saveRDS(motif_data, file = "../data/basic/all_hc_motifs_df.RDS")
motif_data = readRDS("../data/basic/all_hc_motifs_df.RDS")

# distribution of scores 
p_1 = ggplot(data = motif_data, aes(x = as.numeric(perc_occurance))) +
   geom_histogram(alpha = 0.5, binwidth = 1, breaks=seq(0, 100, by = 2), 
                  position = "identity", color = "black",  fill = "blue") + 
   labs(x="proportion of seqs with >90% match") +
   labs(title = "PWM score distribution")
   ggsave("../data/figures/hist_pwm_socres.png")


# filter the scores below 10% threshold  
motif_data_filt = which(motif_data$perc_occurance>10)
motif_data_filt = motif_data[motif_data_filt,]
length(motif_data_filt$perc_occurance)
# histogram 
p_1 = ggplot(data = motif_data_filt, aes(x = as.numeric(perc_occurance))) +
   geom_histogram(alpha = 0.5, binwidth = 1, breaks=seq(0, 100, by = 2), 
                  position = "identity", color = "black",  fill = "blue") + 
   labs(x="proportion of seqs with >90% match") +
   labs(title = "PWM score distribution, filtered at 10% threshold")
   ggsave("../data/figures/hist_pwm_socres_filt.png")


# sort data frame by percentage occurance 
motif_data_filt = as.data.frame(lapply(motif_data_filt, unlist))   
motif_data_filt = motif_data_filt[order(motif_data_filt[,2]),]    

   
### Plot heatmaps for top/bottom scoring motifs 

## make a subset of human motifs
indices = seq(1, length(motif_data_filt$perc_occurance), by = 10)
motif_data_subset = motif_data_filt[indices,]$motif_name
hs_data_pwm_subset = hs_data_pwm[which(names(hs_data_pwm) %in% motif_data_subset)]

for(i in c(1:length(hs_data_pwm_subset))){
pbs_scores = motifScanScores(TSS_prom_seqs, motifPWM = hs_data_pwm_subset[[i]])

# order sequences according to maximum score (max row score used)
pbs_scores_ord = split(pbs_scores, rep(1:nrow(pbs_scores), each = ncol(pbs_scores)))
pbs_scores_ord = order(unlist((lapply(pbs_scores_ord, max))))
pbs_scores = pbs_scores[order(pbs_scores_ord),]
 
# construct heatmaps 
hm.l = new("Heatmap", image = pbs_scores, coords = as.integer(c(-250, 250)), nseq = nrow(pbs_scores), label = paste(names(hs_data_pwm_subset[i]), "pwm", sep = " "), metadata = list())

# set smoothing and plotting
hm_smoothed.l = smoothHeatmap(hm.l, output.size = c(floor(length(TSS_prom_seqs)/2), 250))
scale(hm_smoothed.l) = c(40, 70)

png(paste0("../data/qc/top-bottom_hms/", names(hs_data_pwm_subset[i]), ".png"), 
    height=20, width=20, units="cm", res=300)
plotHeatmapList(hm_smoothed.l, color = "PuBu", legend = TRUE, legend.width = 0.3)
dev.off()
}


## apply k-means instead of sorting sequences by score 

for(i in c(1:length(hs_data_pwm_subset))){
pbs_scores = motifScanScores(TSS_prom_seqs, motifPWM = hs_data_pwm_subset[[i]])

#cluster samples
TSS_prom_seqs_subset = subseq(TSS_prom_seqs, start=150, end=300)   
pbs_scores = motifScanScores(TSS_prom_seqs, motifPWM = hs_data_pwm_subset[[i]])
pbs_scores_subset = motifScanScores(TSS_prom_seqs_subset, motifPWM = hs_data_pwm_subset[[i]])

clusters = kmeans(pbs_scores_subset, centers = 2)
if (clusters$ifault != 0) {
   print("clustering unsuccessful")
   next
   }
mat = pbs_scores[order(clusters$cluster),]

# construct heatmaps 
hm.l = new("Heatmap", image = mat, coords = as.integer(c(-250, 250)), nseq = nrow(pbs_scores), label = paste(names(hs_data_pwm_subset[i]), "pwm", sep = " "), metadata = list())

# set smoothing and plotting
hm_smoothed.l = smoothHeatmap(hm.l, output.size = c(floor(length(TSS_prom_seqs)/2), 250))
scale(hm_smoothed.l) = c(40, 60)

png(paste0("../data/qc/top-bottom_hms/kmeans/", names(hs_data_pwm_subset[i]), ".png"), 
    height=20, width=20, units="cm", res=300)
plotHeatmapList(hm_smoothed.l, color = "PuBu", legend = TRUE, legend.width = 0.3, 
                partition = clusters$size, partition.lines = TRUE, 
                partition.legend = TRUE, legend.pos = "r")
dev.off()

}

## export promoter sequences as FASTA file for analysis with MEME
## motif search summary file can be found at ../data/analysis/meme_ChIP
for(i in 1:length(TSS_prom_seqs)){
   id = paste(">", i, sep = "")
   cat(id, as.character(TSS_prom_seqs[[i]]), sep = "\n", 
   file = "../data/analysis/meme_prom_seqs.fasta", append = TRUE)
}

```

## Chromatin modifications
Extract all available chromatin marks (.bam alignment files) for given cell lines from the ENCODE website. Process data into format compatible with the STAN package input. Promoter sequences are extended to 1 kb upstream/downstream TSS and split into 100-nt bins. For each bin, number of overpals with ChIP-Seq reads (GAlignment objects; 36-nt window) is calculated. 
For each cell line/mark combination, a matrix is produced (seqs x bins). The matrices are then combined into 3-dimensional array and sliced into n matrices (bins x marks), where n is the number of promoters in a given cell line. The following script is computationally intense and should be run on a cluster.  
```{r}
library(pacman)
p_load(ChIPseeker, TxDb.Hsapiens.UCSC.hg19.knownGene, BSgenome.Hsapiens.UCSC.hg19, clusterProfiler, rtracklayer, GenomicRanges, ENCODExplorer, ggplot2, dplyr, reshape, heatmaps, abind)
txdb = TxDb.Hsapiens.UCSC.hg19.knownGene
genome = BSgenome.Hsapiens.UCSC.hg19
ENCODE_promoters = readRDS("../data/basic/ENCODE_promoters.rds")

### extend promoter regions to 2.5kb 
ENCODE_promoters_ext = lapply(ENCODE_promoters, function(x){ranges(x)+2250})
ENCODE_promoters_ext = lapply(seq_along(ENCODE_promoters_ext),function(x){ENCODE_promoters_ext[[x]]=GRanges(seqnames=seqnames(ENCODE_promoters[[x]]), ranges=ENCODE_promoters_ext[[x]], seqlengths=seqlengths(genome))})
chr_set = paste("chr", c(1:22), sep = "")
for(i in 1:length(ENCODE_promoters_ext)){seqlevels(ENCODE_promoters_ext[[i]], pruning.mode="coarse")=chr_set}

histone_marks = c("H3K4me3", "H3K36me3", "H3K4me1", "H3K27me3", "H3K9ac", "H2AFZ", "H4K20me1", "H3K9me3", "H3K4me2", "H3K27ac", "H3K79me2", "H3K9me1")
cell_lines = c("K562", "HepG2", "A549", "GM12878", "MCF-7")
names(ENCODE_promoters_ext) = cell_lines
saveRDS(ENCODE_promoters_ext, "../data/basic/ENCODE_promoters_ext.rds")

### ENCODEexplorer package for data retrieval 
data(encode_df, package = "ENCODExplorer")

.query_results = function(x){
   query_results = queryEncode(df=encode_df, organism = "Homo sapiens", biosample_name = cell_lines[i], target = histone_marks[[x]], assay = "ChIP-seq", file_format = "bam", fixed = TRUE)
   query_results = query_results[assembly=="hg19"]
   return(query_results)
}

qr_list = list()
for(i in 1:length(cell_lines)){
   query_results = lapply(seq_along(histone_marks), .query_results)
   query_results = do.call(args=query_results, what=rbind)
   qr_list[[i]] = query_results 
}
qr_list = do.call(args=qr_list, what=rbind)
# drop MCF-7 cell line
qr_list = qr_list[biosample_name != "MCF-7"]

## retrieve control files 
.control_results = function(x){
   control_results = queryEncode(df=encode_df, organism = "Homo sapiens", biosample_name = cell_lines[x], target = "Control", 
                                 assay = "ChIP-seq", file_format = "bam", fixed = TRUE)
   control_results = control_results[assembly=="hg19"]
   return(control_results)
}
control_list = lapply(seq_along(cell_lines), .control_results)
control_list = do.call(args=control_list, what=rbind)
# keep control files for our samples only
control_list = control_list[accession %in% qr_list$controls]
acc = c("ENCSR000AKY", "ENCSR000AME", "ENCSR000ASS", "ENCSR000AKJ")
control_list = control_list[accession %in% acc]
qr_list = rbind(qr_list, control_list)

## heatmap of histone marks across cell types 
sbst = matrix(, nrow = length(histone_marks), ncol = length(cell_lines))
for(i in 1:length(histone_marks)){
   for(j in 1:length(cell_lines)){
      sbst[i,j] = length(qr_list[biosample_name==cell_lines[j] & target==histone_marks[i]]$accession)
   }
}
colnames(sbst) = cell_lines
row.names(sbst) = histone_marks
sbst = melt(sbst)

g1 = ggplot(data = sbst, aes(X2, X1, fill = value)) +
   geom_tile(color = "black") + 
   labs(x="Cell Type", y="Histone mark") +
   scale_fill_gradient2(low = "white", mid = "pink", high = "red", midpoint = 3, limit = c(0,6)) + 
   geom_text(aes(X2, X1, label = value), color = "black", size = 4) +
 theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank())
ggsave("../data/analysis/chip_seq_data/hist_mark_heatmap.png")

## txt file for download links 
link_lst = control_list$href
link_lst = lapply(link_lst, function(x) paste("https://www.encodeproject.org", x, sep = ""))
lapply(link_lst, function(x) cat(x, file = "../data/analysis/chip_seq_data/hist_mark_links.txt", 
                                     sep = "\n", append = TRUE))

########################################################
# Construct a data frame with cell lines, modifications, 
# and accession codes (this script can be run on server)
########################################################

### Files on server 
p_load(GenomicAlignments)
# remove samples without index 
accession_codes = qr_list[target != "H3K9me1"]$file_accession
accession_codes = accession_codes[!(accession_codes %in% c("ENCFF386DOZ", "ENCFF001EXQ", "ENCFF000AHU", "ENCFF000ASE", "ENCFF000ARA", "ENCFF000AHC", "ENCFF000BDP"))]

.cl = function(x){
   cell_type = qr_list[file_accession==accession_codes[[x]]]$biosample_name
   return(cell_type)
}
.cl_1 = function(x){
   target = qr_list[file_accession==accession_codes[[x]]]$target
   return(target)
}
cell_type = as.character(lapply(seq_along(accession_codes), .cl))
target = as.character(lapply(seq_along(accession_codes), .cl_1))
cl = data.frame(cbind(cell_type, target), stringsAsFactors = FALSE)
cl["accession"] = accession_codes
cl$cell_type = as.character(cl$cell_type)
cl$target = as.character(cl$target)

# Produce a list of GAlignment objects which are subsequently 
# used to calcuate overlaps with promoter regions. 
.alignmentReader = function(x){
   # specify the file on server to be downloaded 
   query = paste0("scp andrei@10.20.0.42:/mnt/storage/andrei/bam_files/", 
                  accession_codes[[x]], ".bam*", " ../data/analysis/chip_seq_data/bam_files")
   system(query)
   # align to promoter sequences 
   param = ScanBamParam(which=ENCODE_promoters_ext[[cell_type[[1]]]])
   data = paste0("../data/analysis/chip_seq_data/bam_files/", accession_codes[[1]], ".bam")
   index = paste0("../data/analysis/chip_seq_data/bam_files/", accession_codes[[1]], ".bam.bai")
   algn = readGAlignments(data, param=param, index = index)
   # delete files to clean memory
   system("rm ../data/analysis/chip_seq_data/bam_files/*")
   return(algn)
}
hm = lapply(seq_along(accession_codes), .alignmentReader)
names(hm) = accession_codes
saveRDS(hm, "../data/analysis/chip_seq_data/promoters_HM.rds")
hm = readRDS("../data/analysis/chip_seq_data/promoters_HM.rds")


##########################################################################################
# PRODUCE TRAINING DATA MATRICES (run on server: K562_matrix.sh, etc. + total_matrices.sh)
##########################################################################################

.binned_avg = function(x){
cl_subset = subset(cl, cell_type==names(ENCODE_promoters_ext)[x])
bins_promoters = tile(ENCODE_promoters_ext[[x]], 50)
.iterate_codes = function(y){   
   hm_subs = hm[[cl_subset$accession[y]]]
   overlaps = lapply(bins_promoters, function(x){countOverlaps(x, hm_subs)})
   overlaps = do.call(rbind, overlaps)
   binned_list[[i]] = overlaps
}
binned_list = lapply(seq_along(cl_subset$accession), .iterate_codes)
# list of matrices to 3D array 
binned_list = abind(binned_list, along = 3)
dimnames(binned_list)[[3]] = cl_subset$target
binned_list = lapply(seq_along(binned_list[,1,1]), function(x) return(binned_list[x,,]))
return(binned_list)
}

names = paste0(names(ENCODE_promoters_ext)[1], "_", c(1:length(ENCODE_promoters_ext[[1]])))
names(binned_list) = names

names(binned_data) = names(ENCODE_promoters_ext)
saveRDS(binned_data, "../data/analysis/chip_seq_data/binned_data.rds")



# normalisation
.qnorm = function(x){
   colsum = apply(x, 2, sum)
   return(colsum)
}
colsum = t(sapply(data, .qnorm))
colsum_norm = normalize.quantiles(colsum)
norm_factor = colsum/colsum_norm

data_norm = lapply(seq_along(data), function(x) round(data[[x]]/norm_factor[x,], 1))
# remove matrices with NaN values
x=sapply(data_norm, function(x) any(is.nan(x)))
data_norm = data_norm[!x]

################### keep all but the 'worst' sample
data = readRDS("../data/analysis/HMMs/hmm_training/binned_hm_data_K562.rds")
# remove outliers  
cl_spl = split(cl_subset, cl_subset$target)
data = lapply(data, function(z){colnames(z) = cl_subset$accession 
              return(z)})

.remove_outliers = function(x){
   names = c()
   for(i in 1:length(x)){
      #sample 100 seqs 
      spl = sample(data, 100)
      spl = lapply(spl, function(y) y=y[, x[[i]]$accession])
      if(dim(x[[i]])[1]<2){
         names[i] = x[[i]]$accession
         next
      } else {
         v = lapply(spl, function(x) x=abs(var)) 
         v = apply(sapply(v, function(x) apply(x, 1, mean)), 1, mean)
         names[i] = names(which.max(v)) 
      }
   }
   colnames=colnames(data[[1]])[!(colnames(data[[1]]) %in% names)]
   data = lapply(data, function(x) x=x[, colnames])   
   data = lapply(data, function(x){colnames(x)=cl_subset$target[cl_subset$accession %in% colnames]
                                   return(x)})
return(data)
}

data = .remove_outliers(cl_spl)


#################### keep only the 'best' sample 
cl_spl = split(cl_subset, cl_subset$target)
data = lapply(data, function(z){colnames(z) = cl_subset$accession 
              return(z)})

.remove_outliers = function(x){
   names = c()
   for(i in 1:length(x)){
      #sample 100 seqs 
      spl = sample(data, 100)
      spl= lapply(spl, function(y) y=y[, x[[i]]$accession])
      if(dim(x[[i]])[1]<2){
         names[i] = x[[i]]$accession
         next
      } else {
         v = lapply(spl, function(x) x=abs(var(x)))
         v = apply(sapply(v, function(x) apply(x, 1, mean)), 1, mean)
         names[i] = names(which.min(v)) 
      }
   }
   colnames=colnames(data[[1]])[colnames(data[[1]]) %in% names]
   data = lapply(data, function(x) x=x[, colnames])   
   data = lapply(data, function(x){colnames(x)=cl_subset$target[cl_subset$accession %in% colnames]
                                   return(x)})
return(data)
}

data = .remove_outliers(cl_spl)



# remove duplicated genes 
dupl = which(duplicated(ENCODE_promoters[["K562"]]$geneId)) 
data_d = data_norm[-dupl]




```
 
Heatmap of available histone marks v cell lines (number of files in ENCODE database)
```{r fig.width=5, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/chip_seq_data/hist_mark_heatmap.png")
 grid.raster(img)
```


## HMM via STAN package 
The obtained matrices were used for training of a Hidden Markov Model (HMM) which splits bins into a pre-defined number of states (i.e. a state is assigned to each bin). For each cell line, a separate set of models was produced. The STAN package allows to model crhomatin marks via different distributions, including Bernoulli, Poisson-LogNormal, and NegativeBinomial. The Bernoulli model was used for subsequent analysis, since it is quicker to train and signal gets binarised, reducing the amount of noise in the data. Models with varying number of states were produced, and optimal number of states was determined via assessing log-likelihood values. 

After model fitting, the decoding step produced vectors of most likely states for each promoter (50 values per sequence) via the Viterbi algorithm. The state paths were also converted to GRanges objects for downstream analysis. In order to assign biologically meaningful functions to the states obtained from the model, k-modes clustering algorithm was applied to the state vectors (i.e. promoters were grouped based on similarity of their Viterbi paths). Optimal number of promoter groups was determined via the elbow method. After clustring, genes from each promoter group were extracted and analysed through GO annotation.    

```{r}
library(pacman)
p_load(STAN, GenomicRanges, ggplot2, reshape, dplyr, cowplot, gplots, TxDb.Hsapiens.UCSC.hg19.knownGene, clusterProfiler, org.Hs.eg.db, preprocessCore, annotate, R.devices, klaR)

ENCODE_promoters = readRDS("../data/basic/ENCODE_promoters.rds")
ENCODE_promoters = ENCODE_promoters[1:4]
ENCODE_promoters_ext = readRDS("../data/basic/ENCODE_promoters_ext.rds")
ENCODE_promoters = lapply(seq_along(ENCODE_promoters), function(x) ENCODE_promoters[[x]]=subsetByOverlaps(ENCODE_promoters[[x]], ENCODE_promoters_ext[[x]]))
cell_lines = c("K562", "HepG2", "A549", "GM12878")
names(ENCODE_promoters) = cell_lines

#################################################
                   # HMM
#################################################
# Scripts for Hidden Markov Model training + viterbi paths are run 
# on server and can be found in the 'server' directory. 


# determine the optimal number of states in the model (Bayesian Information Criterion)
.calcBIC = function(x){
   logLik = max(x@LogLik)
   nStates = x@nStates 
   bic = round(-2*logLik + 2*nStates)
   print(paste(nStates, bic, sep=" :: "))
}
files = list.files(path = "../data/analysis/HMMs/tmpdir/", pattern = "K562")
files = files[sapply(files, function(x) grepl("HMM", x))]
path = paste0("../data/analysis/HMMs/tmpdir/", files)
models = lapply(path, readRDS)
x = sapply(models, .calcBIC)



###############################
nStates = c(10, 15, 20, 25, 30)


###############
# PLOT HEATMAPS 
###############

.getHMs = function(x){
for(cell_line in c("A549", "K562", "HepG2", "GM12878")){
methods = list("NegativeBinomial", "PoissonLogNormal", "Bernoulli")
path = paste0("../data/analysis/HMMs/hmm_training/binned_hm_data_", cell_line, ".rds")
training_data = readRDS(path)

### calculate average signal + produce heatmaps
path = paste0("../data/analysis/HMMs/Bernoulli/", cell_line, "_", x, "_viterbi.rds") # specify number of states here
print(path)
model_Viterbi = readRDS(path)
avg_signal = getAvgSignal(model_Viterbi, training_data)
avg_signal = avg_signal[, order(names(avg_signal[1,]))]


## specify colour palette
library(gplots)
heat = c("dark blue", "dodgerblue4", "darkred", "red", "orange", "gold", "yellow")
colfct = colorRampPalette(heat)
colpal_statemeans = colfct(200)

## define state order and colors
ord_nb = order(apply(avg_signal, 1, max), decreasing=TRUE)
nStates = x
statecols_nb = rainbow(nStates)
names(statecols_nb) = ord_nb

path = paste0("../data/analysis/HMMs/heatmaps/", cell_line, "_", x, "_Bernoulli.pdf")
pdf(path, width = 20, height = 15)

heatmap.2(log(avg_signal + 1)[as.character(ord_nb),], margins=c(8,7), srtCol=45,
        RowSideColors=statecols_nb[as.character(ord_nb)], dendrogram="row",
        Rowv=TRUE, Colv=FALSE, col=colpal_statemeans, trace="none",
        cellnote=round(avg_signal,1)[as.character(ord_nb),], notecol="black")
dev.off()
   }
}
sapply(nStates, .getHMs)

###############################################
### Cluster promoters based on Viterbi path ###
###############################################

.getClusters = function(states){
for (cell_line in cell_lines){
path = paste0("../data/analysis/HMMs/Bernoulli/", cell_line, "_", states, "_viterbi.rds")   
viterbi_hmm = readRDS(path)
viterbi_mat = do.call(rbind, viterbi_hmm)
### find optimal number of clusters: elbow method 
centers = c(5:20)
set.seed(123)
clust_val = sapply(centers, function(x){clust = kmodes(viterbi_mat, x, iter.max = 15)
                                                   tot_error = do.call(sum, list(clust$withindiff))
                                                   return(tot_error)
})
df = data.frame(centers, clust_val)
plot = ggplot(data=df, aes(x=centers, y=clust_val)) +
   geom_line() +
   geom_point(color="red") + 
   labs(x="number of clusters", y="Between-Cluster SS / Total SS") +
   scale_x_continuous(breaks = seq(0, 20, 1)) +
   theme_bw() +
   ggtitle(paste0(cell_line, "_", states))
ggsave(paste0("../data/analysis/HMMs/GO_analysis/kmodes/", cell_line, "_", states, ".png"))
   } 
}
sapply(nStates, .getClusters)

## partition into 'optimal' clusters/states for each cell line (inferred from elbow method)
optimal_states = list(c(20, 10), c(20, 10), c(20, 10), c(20, 10))
names(optimal_states) = cell_lines

#######################
### GO ANNOTATION ###
#######################

# for each promoter cluster, determine and compare GO terms
.analyseGO = function(cell_line){
print(cell_line)
# load data and produce matrix   
path = paste0("../data/analysis/HMMs/Bernoulli/", cell_line, "_", optimal_states[[cell_line]][1], "_viterbi.rds")
viterbi_hmm = readRDS(path)   
viterbi_mat = do.call(rbind, viterbi_hmm)
clust = kmodes(viterbi_mat, modes = optimal_states[[cell_line]][2], iter.max = 15)

#partition seqs into groups
#seq_id = row.names(viterbi_mat)
groups_list = clust$cluster
#group_df = data.frame(seq_id, groups)
groups_unq = unique(groups_list)

# GO profile for each group of promoters (arg = group)
# txdb = TxDb.Hsapiens.UCSC.hg19.knownGene
all_genes = unique(ENCODE_promoters[[cell_line]]$geneId)
 
for(i in groups_unq){
   seqs_by_group = which(groups_list %in% c(i))
   #seqs_by_group = as.integer((row.names(subset(group_df, groups==i))))
   genes = unique(ENCODE_promoters[[cell_line]][seqs_by_group]$geneId)
   
   # cellular component
   ego1 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  ont = "CC", keyType = 'ENTREZID', 
                   pAdjustMethod = "BH", pvalueCutoff  = 0.05, qvalueCutoff  = 0.05, readable = TRUE)
   
   path = paste0("../data/analysis/HMMs/GO_analysis/", cell_line,  "/CC_group_", i, ".png") 
   print(path)
   bp = barplot(ego1, showCategory=12)
   dp = dotplot(ego1)
   png(path, height=20, width=40, units="cm", res=200)
   print(plot_grid(bp, dp, ncol=2, labels = "AUTO"))
   dev.off()
   
   
   # molecular function 
   ego2 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  
                   ont = "MF", pAdjustMethod = "BH", pvalueCutoff  = 0.05, qvalueCutoff  = 0.05, readable = TRUE)
   path = paste0("../data/analysis/HMMs/GO_analysis/", cell_line,  "/MF_group_", i, ".png")
   print(path)
   bp = barplot(ego2, showCategory=10)
   dp = dotplot(ego2)
   png(path, height=20, width=35, units="cm", res=200)
   print(plot_grid(bp, dp, ncol=2, labels = "AUTO"))
   dev.off()
   
   
   # biological process
   ego3 = enrichGO(gene=genes, OrgDb = org.Hs.eg.db, universe = all_genes,  ont = "BP", 
                   pAdjustMethod = "BH", pvalueCutoff  = 0.1, qvalueCutoff  = 0.05, readable = TRUE)
   path = paste0("../data/analysis/HMMs/GO_analysis/", cell_line,  "/BP_group_", i, ".png")
   print(path)
   bp = barplot(ego3, showCategory=10)
   dp = dotplot(ego3)
   png(path, height=20, width=25, units="cm", res=200)
   print(plot_grid(bp, dp, nrow=2, labels="AUTO"))
   dev.off()
   
   graphics.off()
   }

print(paste0("cell line analysed: ", cell_line))
}
sapply(cell_lines, .analyseGO)


### add a column with group to GRanges object for further analysis
ENCODE_promoters$A549_cell = subsetByOverlaps(ENCODE_promoters$A549_cell, ENCODE_promoters_ext$A549)
ENCODE_promoters$A549_cell$group = group_df$group




```
















A549 heatmap (15 states):
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/heatmaps/A549_15_Bernoulli-1.png")
 grid.raster(img)
```

GM12878: 
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/heatmaps/GM12878_15_Bernoulli-1.png")
 grid.raster(img)
```

HepG2:
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/heatmaps/HepG2_15_Bernoulli-1.png")
 grid.raster(img)
```

Enriched GO terms: 

- A549 cell line, group 3
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/A549/BP_group_3.png")
 grid.raster(img)
```

```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/A549/CC_group_3.png")
 grid.raster(img)
```

- A549, group 10
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/A549/BP_group_10.png")
 grid.raster(img)
```

- HepG2, group 8 
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/HepG2/BP_group_8.png")
 grid.raster(img)
```

```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/HepG2/CC_group_8.png")
 grid.raster(img)
```

- K562, group 8 
```{r fig.width=7, fig.height=5, eval=TRUE, echo=FALSE}
suppressPackageStartupMessages(library(pacman))
p_load(png, grid)
img <- readPNG("../data/analysis/HMMs/GO_analysis/K562/BP_group_8.png")
 grid.raster(img)
```

### Analysis of CpG islands and other features in the context of proposed Markov model 
The above model segmented the core promoter chrmotain region into 15 distinct states with differing parameters. Indeed, this classification is arbitrary to some extent, as there is no sharp distinction between the states in vivo. To verify whether the model produces biologically relevant result, it is necessary to superpose the partitioning with previously analysed features such as CpG islands, expression level, promoter width, etc. 

```{r}
library(pacman)
p_load(klaR)

.calc_rep_mat = function(cell_line){
cell_lines = cell_lines = c("K562", "HepG2", "A549", "GM12878")
optimal_states = list(c(15, 10), c(15, 10), c(15, 10), c(15, 10))
names(optimal_states) = cell_lines

# load data and produce matrix   
path = paste0("../data/analysis/HMMs/Bernoulli/", cell_line, "_", optimal_states[[cell_line]][1], "_viterbi.rds")
viterbi_hmm = readRDS(path)   
viterbi_mat = do.call(rbind, viterbi_hmm)

# transform numbers into categorical values before clustering
viterbi_mat = apply(viterbi_mat, c(1,2), as.character)
set.seed(123)
clust = kmodes(viterbi_mat, modes = optimal_states[[cell_line]][2], iter.max = 15)

#partition seqs into groups
seq_id = row.names(viterbi_mat)
groups = unlist(lapply(seq_id, function(x) clust$cluster[[x]]))
group_df = data.frame(seq_id, groups)
groups = unique(group_df$group)

 
## state combinations by group
.mode = function(x){
  ux = unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

.comp_state_mat = function(x){
m = names(clust$cluster[clust$cluster == x])
mat = viterbi_mat[row.names(viterbi_mat) %in% m,]
rep_vec = apply(mat, 2, .mode)
return(rep_vec)
}

rep_mat = do.call(rbind, lapply(groups, .comp_state_mat))
row.names(rep_mat) = groups
data = list(rep_mat, clust)
return(data)
}
a = .calc_rep_mat("A549")





```


























